\documentclass[11 pt, a4paper]{article}  % list options between brackets
\usepackage[nottoc,notlof,notlot,numbib]{tocbibind}
\usepackage[margin=1.2 in]{geometry}
\usepackage{fancyhdr}
\usepackage{manfnt}
\usepackage{pgf}
\usepackage{amsmath,amssymb,natbib,graphicx}
\usepackage{amsfonts}
\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}
\usepackage{bbm}
\usepackage{hyperref}
\usepackage{float}
\usepackage{mathrsfs} %mathscr{A}

\usepackage{chngpage}
\usepackage{layouts}

\usepackage{times}
\usepackage{latexsym}
\usepackage{caption}
\usepackage{graphicx}

\usepackage{subcaption}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\newtheorem{axiom}{Axiom}[section]
\newtheorem{result}{Result}[section]
\newtheorem{example}{example}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{principle}{Principle}[section]
\newtheorem{theorem}{Theorem}[section]% list packages between braces

% type user-defined commands here
%\newcommand{\vmu}{{\bf \mu}}
%\newcommand{\vtheta1}{{\bf \theta^{(1)}}}
%\newcommand{\vtheta2}{{\bf \theta^{(2)}}}
%\newcommand{\vpi}{{\bf \pi}}}

\newcommand{\gm}{\gamma}


\linespread{1.3}
\begin{document}

\title{Progress Notes}   % type title between braces
\author{Detian Deng}         % type author(s) between braces
\date{\today}    % type date between braces
%\maketitle

%\begin{abstract}
%\end{abstract}

\newpage
\section{Current Model}
Let $S_i = (S_{i1}, \ldots, S_{iK})$, $S_{ik} = 1(\sum_{j=1}^{K}Y_{ij}=k)$, then we have $\pi_k=P(\sum_{j=1}^{K}Y_{ij}=k) = \mathbb{E}(S_i)$, and for each $i = 1,\ldots, n$
\begin{align}
\mathbb{E}(\sum_{k=1}^{K}Y_{ik}) =\sum_{k=1}^K \mu_{ik}(\beta) = \sum_{k=1}^K k\pi_{ik}
\end{align}
Let $\gamma = (\gamma_1,\ldots, \gamma_K)$, where 
\begin{align}
\gamma_k = \frac{\pi_{ik}}{\sum_{k=1}^K \mu_{ik}}>0 \text{ and } \sum_{k=1}^K k\gamma_{k} = 1
\end{align}
Note that although $\pi_i$ is dependent on $\mu_i$, $\gamma$ now can be modeled independent of $\mu_i$, and the $n$ equality constraints on $(\mu_i, \pi_i)$ specified by (1) can be reduced to only 1 equality constraint on $\gamma$ in (2).\\

In the regression setting where g$(\mu_i)=X_i^T\beta$, and g is the logit link function.
\begin{align}
P(L | \mu_i, \pi_i) = & P(L | X_i; \beta, \gamma) \\
= & \int P(L | \phi, \mu_i, \pi_i) P(\phi | \mu_i,\pi_i) d \phi \nonumber \\ 
= & \int P(L | \phi) P(\phi | \mu_i,\pi_i) d \phi \nonumber \\ 
\approx & \frac{1}{H}\sum_{h=1}^H P(L | \phi_i^{(h)}) 
\end{align}

where $\phi_i^{(h)}$ is sampled from $P(\phi | \mu_i = g^{-1}(X_i^T\beta),\pi_i = \gamma \mu_i^T1)$


\newpage
Let $M_i^{GS} \in \{0,1\}^K$ be the observed GS measurement, $M_i^{SS} \in \{0,1\}^K$ be the observed SS measurement, $M_i^{BS} \in \{0,1\}^K$ be the observed BS measurement and $L_i \in \{0,1\}^K$ be the latent status for subject $i$. Let $\gamma \in [0,1]^K$ and $\delta \in [0,1]^K$ represent the True Positive Rate (TPR) and False Positive Rate (FPR) for BS measurements respectively, and let $\eta \in [0,1]^K$ be the TPR for SS measurements. Also, let $\mathbb{L}$ be the set of all allowed values of L, such that $|\mathbb{L}| = J^*$ and $l_j$ be the $j$th element in $\mathbb{L}$.

\subsection{The Likelihood for Cases}
For cases without GS measurements, and under the conditional independence assumption for measurement given latent class, the likelihood function is
\begin{align*}
 P(M_i^{SS},M_i^{BS} | \mu, \pi, \eta, \gamma, \delta) 
 = & \sum_{j = 1}^{J^*}  P(M_i^{SS},M_i^{BS}, l_j | \mu, \pi, \eta, \gamma, \delta)  \\ 
= & \sum_{j = 1}^{J^*} \big[ P(M_i^{SS} | l_j, \eta) P(M_i^{BS} | l_j, \gamma, \delta) P(l_j | \mu, \pi) \big ] 
\end{align*}
\\
where $P(l_j | \mu, \pi)$ is defined using (10), and
\begin{align}
P(M_i^{SS} | l_j, \eta) = & \prod_{k=1}^K P(M_{ik} | l_{jk}, \eta_k) \nonumber \\
 = & \prod_{k=1}^K (\eta_k^{l_{jk}}l_{jk})^{M_{ik}} (1-\eta_k)^{l_{jk}(1-M_{ik})}\\
P(M_i^{BS} | l_j, \gamma, \delta) = & \prod_{k=1}^K P(M_{ik} | l_{jk}, \gamma_k, \delta_k) \nonumber \\
 = & \prod_{k=1}^K (\gamma_k^{l_{jk}} \delta_k^{1-l_{jk}})^{M_{ik}} [(1-\gamma_k)^{l_{jk}} (1-\delta_k)^{1-l_{jk}}]^{1-M_{ik}}
\end{align}
\\
For cases with GS measurements, we have $L_i = M_i^{GS}$, then the likelihood is 
\begin{align*}
 P(M_i^{GS},M_i^{SS},M_i^{BS} | \mu, \pi, \eta, \gamma, \delta) 
= & P(M_i^{SS},M_i^{BS} | M_i^{GS} \eta, \gamma, \delta) P(M_i^{GS} | \mu, \pi)\\
= & P(M_i^{SS}| M_i^{GS}, \eta) P(M_i^{BS} | M_i^{GS}, \gamma, \delta) P(M_i^{GS} | \mu, \pi)
\end{align*}
\\
where $P(M_i^{SS}| M_i^{GS}, \eta)$ is defined using (12), $P(M_i^{BS} | M_i^{GS}, \gamma, \delta)$ is defined using (13), and $P(M_i^{GS} | \mu, \pi)$ is defined using (10).\\

\subsection{The Likelihood for Controls}
For controls, we only have BS measurements and we know that their lungs were not infected. Since $(\mu, \pi)$ are defined for case only, they are not involved in the likelihood for controls, thus the likelihood function is:
\begin{align*}
 P(M_i^{BS} |\gamma, \delta) = & \prod_{k=1}^K \delta_k^{M_{ik}}(1-\delta_k)^{(1-M_{ik})}
\end{align*}
\\



\subsection{The Joint Density}
With the specification of likelihood and prior, we can construct the joint density needed for building the MCMC algorithm. Let $G_i$ be an indicator of whether subject $i$ has GS measurements, and define the following three index sets.
\begin{align*}
I_1 = & \Big \{i \in \{1,2,\ldots, n\}: Y_i=1 \text{ and } G_i=1 \Big\}\\
I_2 = & \Big \{i \in \{1,2,\ldots, n\}: Y_i=1 \text{ and } G_i=0 \Big\}\\
I_3 = & \Big \{i \in \{1,2,\ldots, n\}: Y_i=0 \Big\}
\end{align*}
then we can define the joint density of data and parameters as follow by combining all building blocks together:
\begin{align*}
& P(M,\mu,\pi, \eta, \gamma, \delta) \\
= & \prod_{i\in I_1} P(M_i^{GS},M_i^{SS},M_i^{BS} | \mu, \pi, \eta, \gamma, \delta) 
\prod_{i\in I_2} P(M_i^{SS},M_i^{BS} | \mu, \pi, \eta, \gamma, \delta)
\prod_{i\in I_3} P(M_i^{BS} |\gamma, \delta) P(\mu, \pi, \eta, \gamma, \delta)
\end{align*}
\\
From the form of this model, we can see that the model we proposed incorporates data from all the sources with measurements of varying quality. With the joint density fully specified, we can build up a MCMC algorithm to simulate from the posterior distribution. The details fo the algorithm can be found in the appendix.



\end{document}


%\begin{table}[htbp]
%\begin{adjustwidth}{-0.5in}{-1in}
%\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
%\caption{Summary of the model coefficients and standard error estimates}
%\label{tab: coef}
%
%\begin{tabular}{llllll|lllll} 
%\hline 
% \\
%\hline \\
%\end{tabular}
%\end{minipage}}
%\end{adjustwidth}
%\end{table}



















